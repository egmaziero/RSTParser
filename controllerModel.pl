use strict;use Switch;use Cwd;my $currDir = cwd;my $session = $ARGV[0];my $stringIndex = 38;my $classifierCommand = "weka.jar weka.classifiers.trees.J48";#my $classifierCommand = "weka.jar weka.classifiers.functions.SMO";print "Searching for relations...\n";open(OUT,">>classifications/relationsFound_".$session.".txt");open(SEGMENTS,"<temp/segments_".$session.".seg") or die "Error: can't open segments file for $session\n";my @lines = <SEGMENTS>;close(SEGMENTS);open(SEGMENTSPAT,"<temp/segments_Pattern_".$session.".seg") or die "Error: can't open pattern segments file for $session\n";my @linesPat = <SEGMENTSPAT>;close(SEGMENTSPAT);#MAIN--MAIN--MAIN--MAIN--MAIN--MAIN--MAIN--MAIN--MAIN--MAIN--MAIN--MAIN--MAIN--my @segments;my $indexRelations = 0;my @relations;my @segmentsPat;my $inSentence = 0;my @indexSentence;for(my $s=0; $s<=$#lines; $s++){ 	if ($lines[$s] =~/sentence_/)	{		$inSentence = 1;				@indexSentence = split(/_/,$lines[$s]);		@segments = ();		@segmentsPat = ();	}	if ($lines[$s] =~/End of Sentence/)	{				$inSentence = 0;		open(TMP,">temp/textAndEDUs".$session.".txt") or die "Error: can't create textAndEDUs file $!\n";		for(my $i=1; $i<=$#segments;$i++)		{			print TMP trim($segments[$i])."\n";		}		close(TMP);		for(my $i=1; $i<$#segments;$i++)		{			if (length($segments[$i+1]) > 3)			{				@relations = ();				$indexRelations = 0;				print OUT $i.": ".$segments[$i]."\n";				print OUT ($i+1).": ".$segments[$i+1]."\n";				#verify if it is a Parenthetical relation				my $continue = 1;				system('perl rules.pl "'.$segmentsPat[$i].'***'.$segmentsPat[$i+1].'" > tmpRel');				open(FILE,"<tmpRel"); 				foreach(<FILE>)				{					if (trim($_) !~ /noRelationFound/)					{						$continue = 0;						addResult($i,$i+1,normalizeRelations(trim($_)),"1","Rule","-");					}				}				close(FILE);				unlink("tmpRel");												if ($continue == 1)				{					#FEATURE EXTRACTION					#obtain the text of the sentence					open(SENT,"<temp/sentenceComplete".$indexSentence[1].".txt") or die "Error: can't open sentenceComplete $!\n";					my @sentenceComplete = <SENT>;					close(SENT);					#parse the sentence					my $parseResult = parse($sentenceComplete[0]);					open(SENT,">temp/parsedSentence".$session.".txt") or die "Error creating temp/parsedSentence".$session.".txt $!\n";					print SENT $parseResult;					close(SENT);					my $parsedPath = "temp/parsedSentence".$session.".txt";					#feature extration					system('echo "'.$segments[$i].'***'.$segments[$i+1].'***'.trim( tokenizeSegment( $sentenceComplete[0]) ).'***'.$parsedPath.'***'.$session.'" | perl extractFeaturesIntra.pl');					#obtain the feature vector to keep to increment module					open(F,"<temp/featuresRelation".$session.".arff") or die "Error: can't open file with features to increment module $! \n";					my @f = <F>;					close(F);					my $featureVector;					foreach(@f)					{						if ($_ =~ /^\d+/)						{							$featureVector = trim($_);							last;						}					}									#APPLY PatternBased MODEL					system('perl applyPatternModel.pl "'.$segmentsPat[$i].'***'.$segmentsPat[$i+1].'" > temp/tmpDiZer.txt');					open(DiZer,"<temp/tmpDiZer.txt") or die "Error: can't open tmpDiZer.txt $! \n";					my @results = <DiZer>;					close(DiZer);										foreach(@results)					{						 if (length($_) > 3)						 {							my $relDiZer = normalizeRelations(trim($_));							addResult($i,$i+1,$relDiZer,"1","DiZer",$featureVector);						}					}										#APPLY MODEL					system("perl convertStringToWordVectorRelation.pl temp/featuresRelation".$session.".arff models/dictionaryRelations.dic ".$stringIndex);		 					system("java -classpath /var/www/html/dizer2/bin/weka-3-6-11/".$classifierCommand." -l models/RelationsModel.model -T temp/featuresRelation".$session.".arff_converted.arff -p 0 > temp/relationClassification".$session.".class"); 										open(CLASSIFICATIONS,"<temp/relationClassification".$session.".class") or die "Error: can't open classifications $! \n";					my @classification = <CLASSIFICATIONS>;					close(@classification);					foreach(@classification)					{						#print $_."\n";						if ($_ =~ /\d+\:\?/)						{							my @partes = split(/\s+/,$_);							my @prediction = split(/\:/,trim($partes[3]));							my $confidence = trim($partes[4]);									$prediction[1] = normalizeRelations(trim($prediction[1]));							addResult($i,$i+1,$prediction[1],$confidence,"ML",$featureVector);						}					}				}			}			#listing all predictions			for(my $p=0; $p<$indexRelations; $p++)			{				print OUT $relations[$p]->{s1}." | ".$relations[$p]->{s2}." | ".$relations[$p]->{relation}." | ".$relations[$p]->{confidence}." | ".$relations[$p]->{module}." | ".$relations[$p]->{features}."\n";			}			print OUT "-----------------------------\n";			}	}	if ($inSentence == 1)	{		push(@segments,trim($lines[$s]));		push(@segmentsPat,trim($linesPat[$s]));	}}close(OUT);sub normalizeRelations{	my $relation = shift;	$relation =~ s/\-/_/gi;		if ($relation =~ /^antith/i)	{		$relation = "antithesis_concession_contrast";	}	if ($relation =~ /^conces/i)	{		$relation = "antithesis_concession_contrast";	}	if ($relation =~ /^contra/i)	{		$relation = "antithesis_concession_contrast";	}		if ($relation =~ /^back/i)	{		$relation = "background_circumstance";			}	if ($relation =~ /^circum/i)	{		$relation = "background_circumstance";			}		if ($relation =~ /^interp/i)	{		$relation = "interpretation_evaluation_conclusion";	}	if ($relation =~ /^evalu/i)	{		$relation = "interpretation_evaluation_conclusion";	}	if ($relation =~ /^concl/i)	{		$relation = "interpretation_evaluation_conclusion";	}		if ($relation =~ /^evide/i)	{		$relation = "evidence_justify_explanation";	}	if ($relation =~ /^justif/i)	{		$relation = "evidence_justify_explanation";	}	if ($relation =~ /^explan/i)	{		$relation = "evidence_justify_explanation";	}		if ($relation =~ /^enable/i)	{		$relation = "enablement_motivation_purpose";	}	if ($relation =~ /^motiva/i)	{		$relation = "enablement_motivation_purpose";	}	if ($relation =~ /^purpos/i)	{		$relation = "enablement_motivation_purpose";	}		if ($relation =~ /^condit/i)	{		$relation = "condition_otherwise";	}	if ($relation =~ /^otherw/i)	{		$relation = "condition_otherwise";	}	if ($relation =~ /cause|result/i)	{		$relation = "cause_result";	}	if ($relation =~ /^attrib/i)	{		$relation = "attribution";	}	if ($relation =~ /^compari/i)	{		$relation = "comparison";	}	if ($relation =~ /^elabor/i)	{		$relation = "elaboration";	}		if ($relation =~ /^restat/i)	{		$relation = "restatement";	}	if ($relation =~ /^same/i)	{		$relation = "same_unit";	}	if ($relation =~ /^sequen/i)	{		$relation = "sequence";	}	if ($relation =~ /^summa/i)	{		$relation = "summary";	}		return $relation;}sub addResult{	my $s1 = shift;	my $s2 = shift;	my $relation = shift;	my $confidence = shift;	my $module = shift;	my $features = shift;	print "$confidence ->>>>> $relation\n\n";	$relations[$indexRelations] = 	{		s1 => $s1,		s2 => $s2,		relation => $relation,		confidence => $confidence,		module => $module,		features => $features,	};	$indexRelations++;}sub parse{	my $sentence = shift;	my $tokenized = tokenizeSegment($sentence);	open(FILE,">".$currDir."/temp/tokenized.txt") or die "Error: cannot write tokenized.txt\n";	print FILE trim($tokenized);	close(FILE);			my $commandLX_Parser = "(java -Xmx1000m -cp /var/www/html/dizer2/bin/LX_Parser/stanford-parser-2010-11-30/stanford-parser.jar edu.stanford.nlp.parser.lexparser.LexicalizedParser -tokenized -sentences newline -outputFormat oneline -uwModel edu.stanford.nlp.parser.lexparser.BaseUnknownWordModel /var/www/html/dizer2/bin/LX_Parser/stanford-parser-2010-11-30/cintil.ser.gz ".$currDir."/temp/tokenized.txt > ".$currDir."/temp/parsed.txt) >/dev/null 2>&1";		system($commandLX_Parser);		open(P,"<".$currDir."/temp/parsed.txt") or die "Error: can't open parsed file $1\n";	my $parsing = <P>;	#print $parsing."\n\n";	close(P);	return($parsing);}sub tokenizeSegment{	my $segment = shift;	open(TOK,">".$currDir."/temp/toTokenize.txt") or die "Error creating toTokenize.txt $!\n";	print TOK $segment;	close(TOK);	    	system("cat ".$currDir."/temp/toTokenize.txt | /var/www/html/dizer2/bin/LX_Parser/Tokenizer/run-Tokenizer.sh > ".$currDir."/temp/tokenized.txt 2>/dev/null");    	open(TOKENS,"<".$currDir."/temp/tokenized.txt");    	my @lines =<TOKENS>;    	close(TOKENS);        	$lines[0] =~ s/\*\// /gi;   	$lines[0] =~ s/\\\*/ /gi;         	return $lines[0];}sub trim($){ my $string = shift; $string =~ s/^\s+//; $string =~ s/\s+$//; return $string;}